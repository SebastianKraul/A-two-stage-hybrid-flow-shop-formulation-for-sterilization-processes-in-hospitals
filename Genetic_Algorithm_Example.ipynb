{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afcac4-4fbb-4abb-bfa6-68062dacda98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e7d012-f9f3-4ce2-bbdf-1ab165a0cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA Parameters\n",
    "POPULATION_SIZE = 100 \n",
    "GENES_LENGTH = 100 # must be adjusted according to the instance\n",
    "MUTATION_RATE = 0.4\n",
    "CROSSOVER_RATE = 0.8\n",
    "TOURNAMENT_SIZE = 3\n",
    "OSX_SEGMENT_LENGTH = int(GENES_LENGTH // 3)\n",
    "OPX_SEGMENT_LENGTH = int(GENES_LENGTH // 3)\n",
    "TPX_SEGMENT_LENGTH = int(GENES_LENGTH // 3)\n",
    "MUTATION_SCRAMBLE_LENGTH = int(GENES_LENGTH // 3)\n",
    "MUTATION_INVERSION_LENGTH = int(GENES_LENGTH // 3)\n",
    "MAX_ELITISM_PERCENTAGE = 0.25\n",
    "MIN_ELITISM_PERCENTAGE = 0.05\n",
    "ADJUSTMENT_INTERVAL = 10\n",
    "LOCAL_SEARCH_RATE = 0.0\n",
    "LOCAL_SEARCH_MOVES = 2500\n",
    "GENERATIONS = 600\n",
    "RESTART_INTERVAL = 50\n",
    "MAX_RESTART_ATTEMPTS = 10\n",
    "\n",
    "MUTATION_TYPE = \"flip\"\n",
    "CROSSOVER_TYPE = \"TPX\"\n",
    "SELECTION_TYPE = \"roulette\"\n",
    "\n",
    "TAU = 1\n",
    "\n",
    "\n",
    "\n",
    "# Free space at the two stages\n",
    "D1 = 15\n",
    "D2 = 11000\n",
    "\n",
    "# Print all output\n",
    "DUMMY = False\n",
    "EVOLUTION_PLOT_INTERVAL = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e848d563-3b3b-495c-9a6a-a904af0ebf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instance:\n",
    "    def __init__(self, x):\n",
    "        \"\"\"\n",
    "        Initializes the instance with default values and loads job data from a file.\n",
    "\n",
    "        Args:\n",
    "        x (str): The file name to load job data from.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.J = 0\n",
    "        self.F = 0\n",
    "        self.m1 = 0\n",
    "        self.m2 = 0\n",
    "        self.k1 = 0\n",
    "        self.k2 = 0\n",
    "\n",
    "        self.file = x\n",
    "        self.filename = FOLDER_PATH + x\n",
    "        print(f\"Loading instance from file: {x}\")\n",
    "        self.read_jobs_from_file()\n",
    "        self.lower_bound = self.calculate_lower_bound()\n",
    "        self.jobs = self.sules_rule(self.jobs)\n",
    "        self.SPT_jobs = self.calculate_SPT_jobs()\n",
    "        self.ERD_jobs = self.calculate_ERD_jobs()\n",
    "        self.LPT_jobs = self.calculate_LPT_jobs()\n",
    "        self.TIME_LIMIT = self.calculate_time_limit()\n",
    "        if DUMMY:\n",
    "            print(f\"Time limit: {self.TIME_LIMIT}\")\n",
    "\n",
    "    def calculate_LPT_jobs(self):\n",
    "        jobs = self.jobs.copy()  # Create a copy of self.instance.jobs\n",
    "        jobs = jobs[jobs[:, 1].argsort()[::-1]] - 1\n",
    "\n",
    "        tmp = list(jobs[:, 0])\n",
    "        return tmp\n",
    "\n",
    "    def calculate_time_limit(self):\n",
    "        return min(((5000+TAU*(self.J**2)*((self.m1+self.m2)/2))/1000), 1800)\n",
    "\n",
    "    def calculate_SPT_jobs(self):\n",
    "        jobs = self.jobs.copy()  # Create a copy of self.instance.jobs\n",
    "        jobs = jobs[jobs[:, 1].argsort()] - 1\n",
    "        tmp = list(jobs[:, 0])\n",
    "        return tmp\n",
    "\n",
    "    def calculate_ERD_jobs(self):\n",
    "        jobs = self.jobs.copy()  # Create a copy of self.instance.jobs\n",
    "        jobs = jobs[jobs[:, 3].argsort()] - 1\n",
    "        tmp = list(jobs[:, 0])\n",
    "        return tmp\n",
    "\n",
    "    def read_jobs_from_file(self):\n",
    "        \"\"\"\n",
    "            Reads job data from a file.\n",
    "\n",
    "            Args:\n",
    "            filename (str): Name of the file to read from.\n",
    "\n",
    "            Returns:\n",
    "            tuple: Parameters of the job data and the job data itself.\n",
    "            \"\"\"\n",
    "        try:\n",
    "            with open(self.filename, 'r') as file:\n",
    "                self.J, self.F, self.m1, self.m2, self.k1, self.k2 = map(int, file.readline().split())\n",
    "                self.jobs = np.zeros((self.J, 9))\n",
    "                for i in range(self.J):\n",
    "                    job_info = list(map(float, file.readline().split()))\n",
    "                    self.jobs[i] = job_info\n",
    "            if DUMMY:\n",
    "                print(\n",
    "                    f\"Instance loaded wit J = {self.J}, F = {self.F}, m1 = {self.m1}, m2 = {self.m2}, k1 = {self.k1}, k2 = {self.k2}.\")\n",
    "                print(\"\")\n",
    "        except IOError as e:\n",
    "            print(f\"Error reading from file: {e}\")\n",
    "            return None\n",
    "\n",
    "    def sules_rule(self, jobs):\n",
    "        \"\"\"\n",
    "        Applies Sule's rule to jobs, updating the processing time.\n",
    "\n",
    "        Args:\n",
    "        jobs (numpy.ndarray): Array of job data.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Modified array of job data after applying Sule's rule.\n",
    "        \"\"\"\n",
    "        jobs_sules_rule = jobs.copy()\n",
    "        jobs_sules_rule[:, 1] += jobs_sules_rule[:, 5]\n",
    "        jobs_sules_rule[:, 2] += jobs_sules_rule[:, 6]\n",
    "        jobs_sules_rule = np.delete(jobs_sules_rule, [5, 6], axis=1)\n",
    "        return jobs_sules_rule\n",
    "\n",
    "    def calculate_lower_bound(self):\n",
    "        # Assuming jobs is a 2D array where:\n",
    "        # Column 1 is processing time for stage 1, Column 2 is processing time for stage 2,\n",
    "        # Column 3 is release time, Column 5 is setup time for stage 1, Column 6 is setup time for stage 2.\n",
    "        processing_time_sum = np.sum(self.jobs[:, 1]) + np.sum(self.jobs[:, 2])\n",
    "        release_time_sum = np.sum(self.jobs[:, 3])\n",
    "        setup_time_sum = np.sum(self.jobs[:, 5]) + np.sum(self.jobs[:, 6])\n",
    "\n",
    "        lower_bound = processin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d1919-7644-49a7-a5f0-e4208756d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genetic_Algorithm:\n",
    "    def __init__(self, instance):\n",
    "        self.instance = instance\n",
    "        self.solution_time = 0\n",
    "        self.fitness_time = 0\n",
    "        self.selection_time = 0\n",
    "        self.crossover_time = 0\n",
    "        self.mutation_time = 0\n",
    "        self.local_search_time = 0\n",
    "        self.restart_time = 0\n",
    "        self.population = self.generate_population()\n",
    "        self.population.append(self.instance.SPT_jobs)\n",
    "        self.population.append(self.instance.ERD_jobs)\n",
    "        self.population.append(self.instance.LPT_jobs)\n",
    "        self.elite = []\n",
    "        self.fitness_score = []\n",
    "        self.elitism_percentage = MAX_ELITISM_PERCENTAGE\n",
    "        self.elite_size = int(self.elitism_percentage * POPULATION_SIZE)\n",
    "        self.best_fitness_values = []\n",
    "        self.restart_interval = RESTART_INTERVAL\n",
    "        self.max_restart_attempts = MAX_RESTART_ATTEMPTS\n",
    "        self.current_restart_attempt = 0\n",
    "\n",
    "    def convergence_analysis(self):\n",
    "        generations = range(len(self.best_fitness_values))\n",
    "        plt.plot(generations, self.best_fitness_values)\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Best Fitness Value')\n",
    "        plt.title('Convergence Analysis')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def sensitivity_analysis(self, parameter_values, performance_metrics):\n",
    "        plt.plot(parameter_values, performance_metrics)\n",
    "        plt.xlabel('Parameter Value')\n",
    "        plt.ylabel('Performance Metric')\n",
    "        plt.title('Sensitivity Analysis')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def generate_population(self):\n",
    "        return [np.random.permutation(np.arange(0, GENES_LENGTH, 1)) for _ in range(POPULATION_SIZE - 3)]\n",
    "\n",
    "    def fitness(self, individual):\n",
    "        jobs_rescaled = np.copy(self.instance.jobs)\n",
    "        index_classified_family = self.index_by_family(jobs_rescaled, individual)\n",
    "        jobs_classified = self.classify_jobs(jobs_rescaled, index_classified_family)\n",
    "\n",
    "        # Process Stage 1\n",
    "        Batches, Processing_times, Release_times = self.ordered_batches(jobs_classified, self.instance.F,\n",
    "                                                                        self.instance.k1, 1, D1)\n",
    "        mProcessing_times = self.operating_times_batches(Batches, Processing_times)\n",
    "        mRelease_times = self.operating_times_batches(Batches, Release_times)\n",
    "        scheduled_batches, completion_times_batches = self.schedule_batches_spt(mRelease_times, mProcessing_times,\n",
    "                                                                                self.instance.m1, self.instance.F)\n",
    "\n",
    "        # Calculate completion and starting times for Stage 1\n",
    "        completion_times_stage_1, starting_times, machine_ids = self.calculate_times_for_stage(Batches,\n",
    "                                                                                               scheduled_batches,\n",
    "                                                                                               GENES_LENGTH)\n",
    "\n",
    "        # Process Stage 2\n",
    "        jobs_stage_2_rescaled = self.overwrite_release_times(jobs_rescaled, completion_times_stage_1)\n",
    "        index_classified_family_stage_2 = self.index_by_family(jobs_stage_2_rescaled, individual)\n",
    "        jobs_classified_stage_2 = self.classify_jobs(jobs_stage_2_rescaled, index_classified_family_stage_2)\n",
    "        Batches_stage_2, Processing_times_stage_2, Release_times_stage_2 = self.ordered_batches(jobs_classified_stage_2,\n",
    "                                                                                                self.instance.F,\n",
    "                                                                                                self.instance.k2, 2, D2)\n",
    "        mProcessing_times_stage_2 = self.operating_times_batches(Batches_stage_2, Processing_times_stage_2)\n",
    "        mRelease_times_stage_2 = self.operating_times_batches(Batches_stage_2, Release_times_stage_2)\n",
    "        scheduled_batches_stage_2, completion_times_batches_stage_2 = self.schedule_batches_spt(mRelease_times_stage_2,\n",
    "                                                                                                mProcessing_times_stage_2,\n",
    "                                                                                                self.instance.m2,\n",
    "                                                                                                self.instance.F)\n",
    "\n",
    "        # Calculate completion and starting times for Stage 2\n",
    "        completion_times_stage_2, starting_times_stage_2, machine_ids_stage_2 = self.calculate_times_for_stage(\n",
    "            Batches_stage_2, scheduled_batches_stage_2, GENES_LENGTH)\n",
    "\n",
    "        # Calculate heuristic result and lower bound\n",
    "        return sum(completion_times_stage_2)\n",
    "\n",
    "    def print_individual(self, individual):\n",
    "        jobs_rescaled = self.instance.jobs.copy()\n",
    "        index_classified_family = self.index_by_family(jobs_rescaled, individual)\n",
    "        jobs_classified = self.classify_jobs(jobs_rescaled, index_classified_family)\n",
    "\n",
    "        # Process Stage 1\n",
    "        Batches, Processing_times, Release_times = self.ordered_batches(jobs_classified, self.instance.F,\n",
    "                                                                        self.instance.k1, 1, D1)\n",
    "        mProcessing_times = self.operating_times_batches(Batches, Processing_times)\n",
    "        mRelease_times = self.operating_times_batches(Batches, Release_times)\n",
    "        scheduled_batches, completion_times_batches = self.schedule_batches_spt(mRelease_times, mProcessing_times,\n",
    "                                                                                self.instance.m1, self.instance.F)\n",
    "\n",
    "        # Calculate completion and starting times for Stage 1\n",
    "        completion_times_stage_1, starting_times, machine_ids = self.calculate_times_for_stage(Batches,\n",
    "                                                                                               scheduled_batches,\n",
    "                                                                                               GENES_LENGTH)\n",
    "\n",
    "        # Process Stage 2\n",
    "        jobs_stage_2_rescaled = self.overwrite_release_times(jobs_rescaled, completion_times_stage_1)\n",
    "        index_classified_family_stage_2 = self.index_by_family(jobs_stage_2_rescaled, individual)\n",
    "        jobs_classified_stage_2 = self.classify_jobs(jobs_stage_2_rescaled, index_classified_family_stage_2)\n",
    "        Batches_stage_2, Processing_times_stage_2, Release_times_stage_2 = self.ordered_batches(jobs_classified_stage_2,\n",
    "                                                                                                self.instance.F,\n",
    "                                                                                                self.instance.k2, 2, D2)\n",
    "        mProcessing_times_stage_2 = self.operating_times_batches(Batches_stage_2, Processing_times_stage_2)\n",
    "        mRelease_times_stage_2 = self.operating_times_batches(Batches_stage_2, Release_times_stage_2)\n",
    "        scheduled_batches_stage_2, completion_times_batches_stage_2 = self.schedule_batches_spt(mRelease_times_stage_2,\n",
    "                                                                                                mProcessing_times_stage_2,\n",
    "                                                                                                self.instance.m2,\n",
    "                                                                                                self.instance.F)\n",
    "\n",
    "        # Calculate completion and starting times for Stage 2\n",
    "        completion_times_stage_2, starting_times_stage_2, machine_ids_stage_2 = self.calculate_times_for_stage(\n",
    "            Batches_stage_2, scheduled_batches_stage_2, GENES_LENGTH)\n",
    "        file = f\"GA_{self.instance.file}\"\n",
    "        self.write_solution_file(file, scheduled_batches, scheduled_batches_stage_2, starting_times,\n",
    "                                     completion_times_stage_1, machine_ids, starting_times_stage_2,\n",
    "                                     completion_times_stage_2,\n",
    "                                     machine_ids_stage_2, self.instance.m1, self.instance.m2, self.instance.lower_bound)\n",
    "        self.write_detailed_solution(file, scheduled_batches, scheduled_batches_stage_2, starting_times,\n",
    "                                     completion_times_stage_1, machine_ids, starting_times_stage_2,\n",
    "                                     completion_times_stage_2,\n",
    "                                     machine_ids_stage_2, self.instance.m1, self.instance.m2, self.instance.lower_bound)\n",
    "\n",
    "    def index_by_family(self, jobs, individual):\n",
    "        indexed_jobs = [[] for _ in range(self.instance.F)]\n",
    "        for j in individual:\n",
    "            f = int(jobs[int(j), 4])\n",
    "            indexed_jobs[f - 1].append(int(j))\n",
    "        return indexed_jobs\n",
    "\n",
    "    def classify_jobs(self, jobs, indexed_jobs):\n",
    "        \"\"\"\n",
    "        Classifies jobs by their family.\n",
    "\n",
    "        Args:\n",
    "        jobs (numpy.ndarray): Array of job data.\n",
    "        indexed_jobs (list of list): Indices of jobs classified by family.\n",
    "\n",
    "        Returns:\n",
    "        list of numpy.ndarray: Jobs classified by family.\n",
    "        \"\"\"\n",
    "        jobs_classified = []\n",
    "        for family_indices in indexed_jobs:\n",
    "            jobs_f = jobs[family_indices]\n",
    "            jobs_classified.append(jobs_f)\n",
    "        return jobs_classified\n",
    "\n",
    "    def create_batch_space_limit(self, remaining_jobs, batch_size, stage, delta):\n",
    "        \"\"\"\n",
    "        Creates a batch of jobs considering different job sizes and a space limit.\n",
    "\n",
    "        Args:\n",
    "        remaining_jobs (numpy.ndarray): Array of remaining jobs.\n",
    "        batch_size (int): Maximum size of the batch.\n",
    "        stage (int): The stage for which the batch is being created.\n",
    "        delta (int): The space limit for the batch.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing the batch queue, updated remaining jobs,\n",
    "               maximum processing time, and maximum release time in the batch.\n",
    "        \"\"\"\n",
    "        batch_queue = []\n",
    "        processing_time_q = 0\n",
    "        release_time_q = 0\n",
    "        current_batch_size = 0\n",
    "        while current_batch_size < delta and len(remaining_jobs) >= 1:\n",
    "            j = len(remaining_jobs) - 1\n",
    "            job = remaining_jobs[j]\n",
    "            if current_batch_size + job[4 + stage] > batch_size:\n",
    "                break\n",
    "            if processing_time_q <= job[stage]:\n",
    "                processing_time_q = job[stage]\n",
    "\n",
    "            if release_time_q <= job[3]:\n",
    "                release_time_q = job[3]\n",
    "\n",
    "            batch_queue.append(job[0])\n",
    "            current_batch_size += job[4 + stage]\n",
    "\n",
    "            remaining_jobs = np.delete(remaining_jobs, j, 0)\n",
    "\n",
    "        return batch_queue, remaining_jobs, processing_time_q, release_time_q\n",
    "\n",
    "    def construct_batches(self, jobs, k, stage, delta):\n",
    "        \"\"\"\n",
    "        Generates batches from a list of jobs considering batch size and job sizes.\n",
    "\n",
    "        Args:\n",
    "        jobs (numpy.ndarray): Array of job data.\n",
    "        k (int): Maximum size of the batch.\n",
    "        stage (int): The stage for which the batch is being created.\n",
    "        delta (int): The space limit for the batch.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing the list of batches, processing times, and release times.\n",
    "        \"\"\"\n",
    "        if stage == 1:\n",
    "            jobs_sorted = jobs\n",
    "        else:\n",
    "            jobs_sorted = jobs[jobs[:, 3].argsort()]\n",
    "        batches = []\n",
    "        processing_times = []\n",
    "        release_times = []\n",
    "\n",
    "        while len(jobs_sorted) >= 1:\n",
    "            new_batch, jobs_sorted, p_q, r_q = self.create_batch_space_limit(jobs_sorted, k, stage, delta)\n",
    "            batches.append(new_batch)\n",
    "            processing_times.append(p_q)\n",
    "            release_times.append(r_q)\n",
    "\n",
    "        return batches, processing_times, release_times\n",
    "\n",
    "    def ordered_batches(self, jobs_classified, F, k, stage, delta):\n",
    "        \"\"\"\n",
    "        Organizes batches for each family of jobs.\n",
    "\n",
    "        Args:\n",
    "        jobs_classified (list of numpy.ndarray): List of job arrays classified by family.\n",
    "        F (int): Number of families.\n",
    "        k (int): Maximum size of the batch.\n",
    "        stage (int): The stage for which the batch is being created.\n",
    "        delta (int): The space limit for the batch.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing the list of batches, processing times, and release times for each family.\n",
    "        \"\"\"\n",
    "        batches = []\n",
    "        processing_times = []\n",
    "        release_times = []\n",
    "\n",
    "        for i in range(F):\n",
    "            batches_f, pt_f, rt_f = self.construct_batches(jobs_classified[i], k, stage, delta)\n",
    "            batches.append(batches_f)\n",
    "            processing_times.append(pt_f)\n",
    "            release_times.append(rt_f)\n",
    "\n",
    "        return batches, processing_times, release_times\n",
    "\n",
    "    def operating_times_batches(self, batches, processing_times):\n",
    "        \"\"\"\n",
    "        Calculates the processing times for batches.\n",
    "\n",
    "        Args:\n",
    "        batches (list of list): List of batches, each batch containing job indices.\n",
    "        processing_times (list of list): List of processing times for each batch.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Matrix of processing times for each batch.\n",
    "        \"\"\"\n",
    "        max_rows = self.find_max_sublist_length(batches)\n",
    "        m_processing_times = np.zeros((len(batches), max_rows))\n",
    "\n",
    "        for j, pt_f in enumerate(processing_times):\n",
    "            m_processing_times[j, :len(pt_f)] = pt_f\n",
    "\n",
    "        return m_processing_times\n",
    "\n",
    "    def find_max_sublist_length(self, lst):\n",
    "        \"\"\"\n",
    "        Finds the length of the longest sublist in a list of lists.\n",
    "\n",
    "        Args:\n",
    "        lst (list of list): A list where each element is a sublist.\n",
    "\n",
    "        Returns:\n",
    "        int: The length of the longest sublist. Returns 0 if the list is empty or contains no lists.\n",
    "        \"\"\"\n",
    "        if not isinstance(lst, list):\n",
    "            raise ValueError(\"Input must be a list\")\n",
    "\n",
    "        return max((len(sublist) for sublist in lst if isinstance(sublist, list)), default=0)\n",
    "\n",
    "    def schedule_batches_spt(self, release_times, processing_times, num_machines, num_families):\n",
    "        \"\"\"\n",
    "        Schedules batches on machines using the Shortest Processing Time (SPT) rule.\n",
    "\n",
    "        Args:\n",
    "        release_times (list of list): Release times for each batch in each family.\n",
    "        processing_times (list of list): Processing times for each batch in each family.\n",
    "        num_machines (int): Number of machines available.\n",
    "        num_families (int): Number of families.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing the scheduled jobs and a completion vector.\n",
    "        \"\"\"\n",
    "        jobs = []\n",
    "        for family in range(num_families):\n",
    "            for job, (release_time, processing_time) in enumerate(zip(release_times[family], processing_times[family])):\n",
    "                if release_time != 0:\n",
    "                    jobs.append((family, job, release_time, processing_time))\n",
    "\n",
    "        machines = [(machine_id, 0, 0) for machine_id in range(1, num_machines + 1)]\n",
    "        scheduled_jobs = []\n",
    "        current_time = 0\n",
    "\n",
    "        while jobs:\n",
    "            available_jobs = [job for job in jobs if job[2] <= current_time]\n",
    "\n",
    "            if available_jobs:\n",
    "                shortest_job = min(available_jobs, key=lambda x: x[3])\n",
    "                machines.sort(key=lambda x: x[1])\n",
    "                machine_id, machine_load, last_job_end_time = machines[0]\n",
    "                start_time = max(last_job_end_time, shortest_job[2])\n",
    "\n",
    "                completion_time = start_time + shortest_job[3]\n",
    "                machine_load = completion_time\n",
    "                machines[0] = (machine_id, machine_load, completion_time)\n",
    "\n",
    "                assigned_job = {\n",
    "                    'machine_id': machine_id,\n",
    "                    'start_time': start_time,\n",
    "                    'completion_time': completion_time,\n",
    "                    'family_index': shortest_job[0],\n",
    "                    'job_index': shortest_job[1]\n",
    "                }\n",
    "                jobs.remove(shortest_job)\n",
    "                scheduled_jobs.append(assigned_job)\n",
    "                current_time = max(current_time, min(completion_time, machines[1][1]))\n",
    "            else:\n",
    "                current_time += 1\n",
    "\n",
    "        completion_vector = np.array([job['completion_time'] for job in scheduled_jobs]).reshape(-1, 1)\n",
    "        return scheduled_jobs, completion_vector\n",
    "\n",
    "    def calculate_times_for_stage(self, batches, scheduled_batches, J):\n",
    "        \"\"\"\n",
    "        Calculates the completion and starting times for each stage.\n",
    "\n",
    "        Args:\n",
    "        batches (list of list): List of batches, each batch containing job indices.\n",
    "        scheduled_batches (list of dict): List of dictionaries containing scheduling information.\n",
    "        J (int): Total number of jobs.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing arrays of completion times, starting times, and machine IDs.\n",
    "        \"\"\"\n",
    "        completion_times = np.zeros(J)\n",
    "        starting_times = np.zeros(J)\n",
    "        machine_ids = np.zeros(J)\n",
    "\n",
    "        for batch in scheduled_batches:\n",
    "            machine_id = batch['machine_id']\n",
    "            start_time = batch['start_time']\n",
    "            completion_time = batch['completion_time']\n",
    "            family_index = batch['family_index']\n",
    "            job_index = batch['job_index']\n",
    "\n",
    "            for job in batches[family_index][job_index]:\n",
    "                completion_times[int(job) - 1] = completion_time\n",
    "                starting_times[int(job) - 1] = start_time\n",
    "                machine_ids[int(job) - 1] = machine_id\n",
    "\n",
    "        return completion_times, starting_times, machine_ids\n",
    "\n",
    "    def overwrite_release_times(self, jobs, completion_times):\n",
    "        \"\"\"\n",
    "        Overwrites the release times of jobs for the next stage based on completion times.\n",
    "\n",
    "        Args:\n",
    "        jobs (numpy.ndarray): Array of job data.\n",
    "        completion_times (numpy.ndarray): Array of completion times from the previous stage.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Updated array of job data with new release times.\n",
    "        \"\"\"\n",
    "        jobs_stage_2 = jobs.copy()\n",
    "        jobs_stage_2[:, 3] = completion_times\n",
    "        return jobs_stage_2\n",
    "\n",
    "    def write_solution_file(self, file, scheduled_batches, scheduled_batches_stage_2, starting_times,\n",
    "                            completion_times_stage_1, machine_ids, starting_times_stage_2, completion_times_stage_2,\n",
    "                            machine_ids_stage_2, m1, m2, LB):\n",
    "        \"\"\"\n",
    "        Writes the solution of the scheduling heuristic to a file.\n",
    "\n",
    "        Args:\n",
    "        file (str): Name of the file to write to.\n",
    "        scheduled_batches (list): Scheduled batches for stage 1.\n",
    "        scheduled_batches_stage_2 (list): Scheduled batches for stage 2.\n",
    "        starting_times, completion_times_stage_1, machine_ids, starting_times_stage_2, completion_times_stage_2, machine_ids_stage_2 (list): Various scheduling parameters.\n",
    "        m1, m2 (int): Number of machines in stage 1 and 2.\n",
    "        LB (float): Lower bound of the objective function.\n",
    "\n",
    "        Returns:\n",
    "        None: The function writes to a file and does not return anything.\n",
    "        \"\"\"\n",
    "        results_dir = \"./Results/\"\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        file_path = os.path.join(results_dir, f\"solution_GA_{file}\")\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"w\") as f:\n",
    "                objective = sum(completion_times_stage_2)\n",
    "                comp1 = [batch['completion_time'] for batch in scheduled_batches]\n",
    "                comp2 = [batch['completion_time'] for batch in scheduled_batches_stage_2]\n",
    "                start1 = [batch['start_time'] for batch in scheduled_batches]\n",
    "                start2 = [batch['start_time'] for batch in scheduled_batches_stage_2]\n",
    "                gap = round(abs(objective - LB) / abs(objective), 2)\n",
    "                utilization1 = sum(comp1[i] - start1[i] for i in range(len(comp1))) / ((max(comp1) - min(start1)) * m1)\n",
    "                utilization2 = sum(comp2[i] - start2[i] for i in range(len(comp2))) / ((max(comp2) - min(start2)) * m2)\n",
    "                batch1 = len(scheduled_batches)\n",
    "                batch2 = len(scheduled_batches_stage_2)\n",
    "                timeInSystem = sum(\n",
    "                    completion_times_stage_2[i] - self.instance.jobs[i][3] for i in range(len(completion_times_stage_2))) / len(\n",
    "                    completion_times_stage_2)\n",
    "                f.write(\n",
    "                    f\"{objective} {gap} {utilization1} {utilization2} {batch1} {batch2} {LB} {max(comp1)} {min(start1)} {max(comp2)} {min(start2)} {timeInSystem}\\n\")\n",
    "                # Additional details can be written here if needed\n",
    "        except IOError as e:\n",
    "            print(f\"Error writing to file: {e}\")\n",
    "\n",
    "    def write_detailed_solution(self, file, scheduled_batches, scheduled_batches_stage_2, starting_times,\n",
    "                                completion_times_stage_1, machine_ids, starting_times_stage_2, completion_times_stage_2,\n",
    "                                machine_ids_stage_2, m1, m2, LB):\n",
    "        \"\"\"\n",
    "        Writes a detailed solution of the scheduling heuristic to a file.\n",
    "\n",
    "        Args:\n",
    "        file (str): Name of the file to write to.\n",
    "        scheduled_batches, scheduled_batches_stage_2 (list): Scheduled batches for both stages.\n",
    "        starting_times, completion_times_stage_1, machine_ids, starting_times_stage_2, completion_times_stage_2, machine_ids_stage_2 (list): Various scheduling parameters.\n",
    "        m1, m2 (int): Number of machines in stage 1 and 2.\n",
    "        LB (float): Lower bound of the objective function.\n",
    "\n",
    "        Returns:\n",
    "        None: The function writes to a file and does not return anything.\n",
    "        \"\"\"\n",
    "        results_dir = \"./Results/\"\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        file_path = os.path.join(results_dir, f\"detailed_solution_GA_{file}\")\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"w\") as f:\n",
    "                for i, job in enumerate(self.instance.jobs):\n",
    "                    f.write(\n",
    "                        f\"{i} {job[0]} {job[1]} {job[2]} {job[3]} {job[4]} {job[5]} {job[6]} {starting_times[i]} {completion_times_stage_1[i]} {starting_times_stage_2[i]} {completion_times_stage_2[i]}\\n\")\n",
    "        except IOError as e:\n",
    "            print(f\"Error writing to file: {e}\")\n",
    "\n",
    "    def _old_osx_crossover(self, parent1, parent2):\n",
    "        crossover_point = np.random.randint(GENES_LENGTH - OSX_SEGMENT_LENGTH)\n",
    "        child = parent1[crossover_point:crossover_point + OSX_SEGMENT_LENGTH]\n",
    "\n",
    "        # Initialize a list to keep track of which elements are already in the child\n",
    "        used_elements = set(child)\n",
    "\n",
    "        # Iterate through parent2 and add unused elements to the child\n",
    "        index = 0\n",
    "        start = []\n",
    "        while len(start) < crossover_point:\n",
    "            if parent2[index] not in used_elements:\n",
    "                start.append(int(parent2[index]))\n",
    "                used_elements.add(parent2[index])\n",
    "            index += 1\n",
    "\n",
    "        while len(used_elements) < GENES_LENGTH:\n",
    "            if parent2[index] not in used_elements:\n",
    "                child = np.concatenate((child, [int(parent2[index])]))\n",
    "                used_elements.add(parent2[index])\n",
    "            index += 1\n",
    "\n",
    "        child = np.concatenate((start, child))\n",
    "        return child\n",
    "\n",
    "    # One-Point Order Crossover\n",
    "    def opx_crossover(self, parent1, parent2):\n",
    "        crossover_point = np.random.randint(OPX_SEGMENT_LENGTH, GENES_LENGTH - OPX_SEGMENT_LENGTH)\n",
    "        child = parent1[:crossover_point]\n",
    "        # Initialize a list to keep track of which elements are already in the child\n",
    "        used_elements = set(child)\n",
    "        # Iterate through parent2 and add unused elements to the child\n",
    "        index = 0\n",
    "        while len(used_elements) < GENES_LENGTH:\n",
    "            if parent2[index] not in used_elements:\n",
    "                child = np.concatenate((child, [int(parent2[index])]))\n",
    "                used_elements.add(parent2[index])\n",
    "            index += 1\n",
    "\n",
    "        return child\n",
    "\n",
    "    # Two-Point Order Crossover\n",
    "    def tpx_crossover(self, parent1, parent2):\n",
    "        crossover_point_1 = np.random.randint(GENES_LENGTH - TPX_SEGMENT_LENGTH)\n",
    "        crossover_point_2 = np.random.randint(crossover_point_1 + TPX_SEGMENT_LENGTH, GENES_LENGTH)\n",
    "        child = parent1[crossover_point_1:crossover_point_2]\n",
    "\n",
    "        # Initialize a list to keep track of which elements are already in the child\n",
    "        used_elements = set(child)\n",
    "\n",
    "        # Iterate through parent2 and add unused elements to the child\n",
    "        index = 0\n",
    "        start = []\n",
    "        while len(start) < crossover_point_1:\n",
    "            if parent2[index] not in used_elements:\n",
    "                start.append(int(parent2[index]))\n",
    "                used_elements.add(parent2[index])\n",
    "            index += 1\n",
    "\n",
    "        while len(used_elements) < GENES_LENGTH:\n",
    "            if parent2[index] not in used_elements:\n",
    "                child = np.concatenate((child, [int(parent2[index])]))\n",
    "                used_elements.add(parent2[index])\n",
    "            index += 1\n",
    "\n",
    "        child = np.concatenate((start, child))\n",
    "        return child\n",
    "\n",
    "    def crossover(self, parent1, parent2):\n",
    "        crossover_type = CROSSOVER_TYPE  # np.random.choice(['inversion', 'scramble', 'flip'])\n",
    "        if crossover_type == 'OPX':\n",
    "            child = self.opx_crossover(parent1, parent2)\n",
    "        elif crossover_type == 'TPX':\n",
    "            child = self.tpx_crossover(parent1, parent2)\n",
    "        return child\n",
    "\n",
    "    # Insertion Mutation\n",
    "    def insert_mutation(self, individual):\n",
    "        # Select mutation point\n",
    "        mutation_point = np.random.randint(GENES_LENGTH)\n",
    "        # Select insertion point\n",
    "        insertion_point = np.random.randint(GENES_LENGTH)\n",
    "\n",
    "        # Perform mutation\n",
    "        gene_to_insert = individual[mutation_point]\n",
    "        individual = np.delete(individual, mutation_point)\n",
    "        individual = np.insert(individual, insertion_point, gene_to_insert)\n",
    "\n",
    "        return individual\n",
    "\n",
    "    # Flip Mutation\n",
    "    def flip_mutation(self, individual):\n",
    "        mutation_indices = np.random.choice(range(GENES_LENGTH), size=2, replace=False)\n",
    "        _ = individual[mutation_indices[0]]\n",
    "        individual[mutation_indices[0]] = individual[mutation_indices[1]]\n",
    "        individual[mutation_indices[1]] = _\n",
    "        return individual\n",
    "\n",
    "    # Inversion Mutation\n",
    "    def inversion_mutation(self, individual):\n",
    "        mutation_indices = sorted(np.random.choice(range(GENES_LENGTH), size=2, replace=False))\n",
    "        individual[mutation_indices[0]:mutation_indices[1] + 1] = individual[\n",
    "                                                                  mutation_indices[0]:mutation_indices[1] + 1][::-1]\n",
    "        return individual\n",
    "\n",
    "        # Scramble Mutation\n",
    "\n",
    "    def scramble_mutation(self, individual):\n",
    "        mutation_point_1 = np.random.randint(GENES_LENGTH-MUTATION_SCRAMBLE_LENGTH)\n",
    "        mutation_point_2 = np.random.randint(mutation_point_1 + MUTATION_SCRAMBLE_LENGTH, GENES_LENGTH)\n",
    "        subsequence = individual[mutation_point_1:mutation_point_2]\n",
    "        np.random.shuffle(subsequence)\n",
    "        individual[mutation_point_1:mutation_point_2] = subsequence\n",
    "        return individual\n",
    "\n",
    "    # Mutation operation\n",
    "    def mutate(self, individual):\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            mutated_individual = individual.copy()\n",
    "            # Randomly select mutation type\n",
    "            mutation_type = MUTATION_TYPE  # np.random.choice(['inversion', 'scramble', 'flip'])\n",
    "            if mutation_type == 'inversion':\n",
    "                mutated_individual = self.inversion_mutation(mutated_individual)\n",
    "            elif mutation_type == 'scramble':\n",
    "                mutated_individual = self.scramble_mutation(mutated_individual)\n",
    "            elif mutation_type == 'flip':\n",
    "                mutated_individual = self.flip_mutation(mutated_individual)\n",
    "            elif mutation_type == 'insert':\n",
    "                mutated_individual = self.insert_mutation(mutated_individual)\n",
    "            return mutated_individual\n",
    "        return individual\n",
    "    # Selection operation: Tournament selection\n",
    "    def tournament_selection(self):\n",
    "        parents = []\n",
    "        # Ensure an even number of parents by adjusting if necessary\n",
    "        if POPULATION_SIZE % 2 != 0:\n",
    "            parents.append(np.random.randint(POPULATION_SIZE))\n",
    "        while len(parents) < POPULATION_SIZE:\n",
    "            tournament_indices = np.random.choice(range(POPULATION_SIZE), size=TOURNAMENT_SIZE, replace=False)\n",
    "            tournament_scores = [self.fitness_scores[i] for i in tournament_indices]\n",
    "            winner_index = tournament_indices[np.argmax(tournament_scores)]\n",
    "            parents.append(winner_index)\n",
    "        return parents\n",
    "\n",
    "    # Selection operation: Roulette wheel selection\n",
    "    def roulette_wheel_selection(self):\n",
    "        total_fitness = sum(self.fitness_scores)\n",
    "        probabilities = [score / total_fitness for score in self.fitness_scores]\n",
    "        parents = np.random.choice(range(POPULATION_SIZE), size=POPULATION_SIZE, p=probabilities)\n",
    "        return parents\n",
    "\n",
    "    # Determine selection method dynamically\n",
    "    def determine_selection_method(self, generation):\n",
    "        selection_type = SELECTION_TYPE\n",
    "        if selection_type == 'tournament':\n",
    "            parents = self.tournament_selection()\n",
    "            return parents\n",
    "        elif selection_type == 'roulette':\n",
    "            parents = self.roulette_wheel_selection()\n",
    "            return parents\n",
    "\n",
    "    def hill_climbing_local_search(self, individual):\n",
    "        # Evaluate the fitness of the current individual\n",
    "        current_fitness = self.fitness(individual)\n",
    "        cnt = 0\n",
    "\n",
    "        # Get the indices of the genes\n",
    "        gene_indices1 = np.arange(len(individual))\n",
    "        np.random.shuffle(gene_indices1)\n",
    "        gene_indices2 = np.arange(len(individual))\n",
    "        np.random.shuffle(gene_indices2)\n",
    "        # Iterate over each gene in the individual\n",
    "        for gene_index in gene_indices1:\n",
    "            # Try moving the gene to all possible positions within the individual\n",
    "            for new_position in gene_indices2:\n",
    "                # Skip if the new position is the same as the current position\n",
    "                if new_position == gene_index:\n",
    "                    continue\n",
    "\n",
    "                cnt += 1\n",
    "                # Move the gene to the new position\n",
    "                new_individual = np.copy(individual)\n",
    "                gene_value = new_individual[gene_index]\n",
    "                new_individual = np.delete(new_individual, gene_index)\n",
    "                new_individual = np.insert(new_individual, new_position, gene_value)\n",
    "\n",
    "                # Evaluate the fitness of the new individual\n",
    "                new_fitness = self.fitness(new_individual)\n",
    "\n",
    "                # If the new individual has better fitness, accept the move\n",
    "                if new_fitness < current_fitness:\n",
    "                    if DUMMY:\n",
    "                        print(f\"Improvement in local search: {new_fitness - current_fitness}\")\n",
    "                    individual = new_individual\n",
    "                    current_fitness = new_fitness\n",
    "                if cnt > LOCAL_SEARCH_MOVES:\n",
    "                    return individual\n",
    "        return individual\n",
    "\n",
    "    def should_restart(self):\n",
    "        # Check if the algorithm should restart based on a predefined condition\n",
    "        # For example, lack of improvement in best fitness over multiple generations\n",
    "        return self.current_restart_attempt < self.max_restart_attempts\n",
    "\n",
    "    def restart_algorithm(self, elite_population):\n",
    "        # Reset algorithm state by generating a new population\n",
    "        self.population = self.regenerate_population(elite_population)\n",
    "        self.current_restart_attempt += 1\n",
    "\n",
    "    def regenerate_population(self, elite_population):\n",
    "        tmp = elite_population.copy()\n",
    "        for i in elite_population:\n",
    "            tmp.append(self.insert_mutation(i.copy()))\n",
    "            tmp.append(self.scramble_mutation(i))\n",
    "        tmp.append(self.instance.calculate_SPT_jobs())\n",
    "        tmp.append(self.instance.calculate_ERD_jobs())\n",
    "        tmp.append(self.instance.calculate_LPT_jobs())\n",
    "        tmp.extend([np.random.permutation(np.arange(0, GENES_LENGTH, 1)) for _ in\n",
    "                    range(POPULATION_SIZE - len(tmp))])\n",
    "        return tmp\n",
    "\n",
    "    def run(self):\n",
    "        trggr = False\n",
    "        previous = np.inf\n",
    "        self.solution_time = time.time()\n",
    "        generation = 0\n",
    "        restart = 0\n",
    "        while time.time() - self.solution_time < self.instance.TIME_LIMIT:\n",
    "        #for generation in range(GENERATIONS):\n",
    "            generation += 1\n",
    "            restart += 1\n",
    "            if DUMMY:\n",
    "                print(f\"Generation: {generation}\")\n",
    "\n",
    "            tmp = time.time()\n",
    "            self.fitness_scores = [self.fitness(individual) for individual in self.population]\n",
    "            self.fitness_time += time.time() - tmp\n",
    "\n",
    "            best = np.min(self.fitness_scores)\n",
    "            if DUMMY:\n",
    "                print(f\"New best fitness: {best}\")\n",
    "                print(f\"Gap: {round(abs(best - self.instance.lower_bound) / abs(best), 4)}\")\n",
    "            if best < previous:\n",
    "                trggr = True\n",
    "                restart = 1\n",
    "            self.best_fitness_values.append(best)\n",
    "            previous = best\n",
    "\n",
    "            # Adjust elitism every ADJUSTMENT_INTERVAL generations\n",
    "            if generation % ADJUSTMENT_INTERVAL == -1:\n",
    "                # Calculate average fitness and adjust elitism percentage\n",
    "                self.elitism_percentage = min(MAX_ELITISM_PERCENTAGE,\n",
    "                                              max(MIN_ELITISM_PERCENTAGE,\n",
    "                                                  (np.min(self.fitness_scores) - self.instance.lower_bound) / np.min(self.fitness_scores)))\n",
    "                self.elite_size = int(self.elitism_percentage * POPULATION_SIZE)\n",
    "\n",
    "            # Elitism: Preserve top individuals\n",
    "\n",
    "            elite_indices = np.argsort(self.fitness_scores)[:self.elite_size]\n",
    "\n",
    "            elite_population = [self.population[i].copy() for i in elite_indices]\n",
    "\n",
    "            tmp = time.time()\n",
    "            if trggr:\n",
    "                elite_population[0] = self.hill_climbing_local_search(elite_population[0])\n",
    "                trggr = False\n",
    "            self.local_search_time += time.time() - tmp\n",
    "\n",
    "            tmp = time.time()\n",
    "            # Check if restart condition is met\n",
    "            if restart % self.restart_interval == 0 or len(set(self.fitness_scores)) < POPULATION_SIZE//2:\n",
    "                if self.should_restart():\n",
    "                    if DUMMY:\n",
    "                        print(\"Restart the algorithm!\")\n",
    "                    self.restart_algorithm(elite_population)\n",
    "                    self.fitness_scores = [self.fitness(individual) for individual in self.population]\n",
    "                    elite_indices = np.argsort(self.fitness_scores)[:self.elite_size]\n",
    "                    elite_population = [self.population[i].copy() for i in elite_indices]\n",
    "                    restart = 0\n",
    "            self.restart_time += time.time() - tmp\n",
    "\n",
    "            tmp = time.time()\n",
    "            # Determine selection method for current generation\n",
    "            # selected_parents_indices = self.determine_selection_method(generation)\n",
    "            selected_parents_indices = self.roulette_wheel_selection()\n",
    "            self.selection_time += time.time() - tmp\n",
    "\n",
    "            tmp = time.time()\n",
    "            # Crossover\n",
    "            children = []\n",
    "            for i in range(0, len(selected_parents_indices), 2):\n",
    "                parent1_index = selected_parents_indices[i]\n",
    "                parent2_index = selected_parents_indices[i + 1]\n",
    "                parent1 = self.population[parent1_index]\n",
    "                parent2 = self.population[parent2_index]\n",
    "                if np.random.rand() < CROSSOVER_RATE:\n",
    "                    # child1 = self.osx_crossover(parent2, parent1)\n",
    "                    # child2 = self.osx_crossover(parent1, parent2)\n",
    "                    child1 = self.crossover(parent1, parent2)\n",
    "                    child2 = self.crossover(parent2, parent1)\n",
    "                    children.append(child1)\n",
    "                    children.append(child2)\n",
    "                else:\n",
    "                    children.extend([parent1, parent2])\n",
    "            self.crossover_time += time.time() - tmp\n",
    "\n",
    "            # Adjust the number of children to maintain a fixed population size\n",
    "            children = children[:POPULATION_SIZE - self.elite_size]\n",
    "\n",
    "            tmp = time.time()\n",
    "            # Mutation\n",
    "            for i in range(len(children)):\n",
    "                children[i] = self.mutate(children[i])\n",
    "            self.mutation_time += time.time() - tmp\n",
    "\n",
    "            # Replace old population with new population\n",
    "            self.population = elite_population + children\n",
    "\n",
    "            # Apply hill climbing local search to a portion of the population\n",
    "            # for i in range(self.elite_size, POPULATION_SIZE):\n",
    "            #     if np.random.rand() < LOCAL_SEARCH_RATE:\n",
    "            #         self.population[i] = self.hill_climbing_local_search(self.population[i])\n",
    "\n",
    "\n",
    "            # Return best individual\n",
    "        best_individual_index = np.argmin([self.fitness(individual) for individual in self.population])\n",
    "        self.solution_time = time.time() - self.solution_time\n",
    "        if DUMMY:\n",
    "            self.convergence_analysis()\n",
    "        self.report()\n",
    "        self.print_individual(self.population[best_individual_index])\n",
    "        return best # self.population[best_individual_index]\n",
    "\n",
    "    def report(self):\n",
    "        print(f\"Solution time: {self.solution_time}\")\n",
    "        print(f\"Fitness time: {self.fitness_time}\")\n",
    "        print(f\"Selection time: {self.selection_time}\")\n",
    "        print(f\"Crossover time: {self.crossover_time}\")\n",
    "        print(f\"Mutation time: {self.mutation_time}\")\n",
    "        print(f\"Restart time: {self.restart_time}\")\n",
    "        print(f\"Local search time: {self.local_search_time}\")\n",
    "        print(f\"Total time: {self.fitness_time + self.crossover_time + self.mutation_time + self.local_search_time+ self.selection_time + self.restart_time}\")\n",
    "        print(\n",
    "            f\"Best individual: {self.population[np.argmin([self.fitness(individual) for individual in self.population])]}\\n\")\n",
    "        print(\n",
    "            f\"Best fitness: {self.fitness(self.population[np.argmin([self.fitness(individual) for individual in self.population])])}\")\n",
    "        print(f\"Gap: {round(abs(self.best_fitness_values[-1] - self.instance.lower_bound) / abs(self.best_fitness_values[-1]), 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f624e6-546e-4761-a377-0260bad48947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global GENES_LENGTH\n",
    "    global FOLDER_PATH\n",
    "    global FILES\n",
    "    global TXT_FILES\n",
    "    global TPX_SEGMENT_LENGTH\n",
    "    global MUTATION_SCRAMBLE_LENGTH\n",
    "    global MUTATION_INVERSION_LENGTH\n",
    "    FOLDER_PATH = f\"./Data/J_250/\" # must be adjusted according to the data\n",
    "    FILES = os.listdir(FOLDER_PATH)\n",
    "    TXT_FILES = [f for f in FILES if f.endswith('.txt')]   \n",
    "    with open(results_file, \"w\") as f:\n",
    "        for i in TXT_FILES:\n",
    "            inst = Instance(i)\n",
    "            GENES_LENGTH = inst.J\n",
    "            TPX_SEGMENT_LENGTH = int(GENES_LENGTH // 3)\n",
    "            MUTATION_SCRAMBLE_LENGTH = int(GENES_LENGTH // 3)\n",
    "            MUTATION_INVERSION_LENGTH = int(GENES_LENGTH // 3)\n",
    "            ga = Genetic_Algorithm(inst)\n",
    "            bst = ga.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ddbf2-2566-4919-8018-e9281d203c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":   \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836a2ff-3178-44e7-9c56-d90c68e13267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
